{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "train_ratio: 0.03\n",
      "WARNING:tensorflow:tf.op_scope(values, name, default_name) is deprecated, use tf.name_scope(name, default_name, values)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\softwareInstall\\Anaconda3\\envs\\localpython\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "E:\\softwareInstall\\Anaconda3\\envs\\localpython\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 2.24466 train_acc= 0.10606 val_acc= 0.17195 val_auc= 0.60755 time= 1.28955\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.0, 6: 0.0, 2: 0.88, 5: 0.0, 1: 0.0, 4: 0.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.14, 0: 0.0, 5: 0.08, 4: 0.88, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0002 train_loss= 2.17813 train_acc= 0.18182 val_acc= 0.15385 val_auc= 0.61086 time= 1.62962\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.0, 6: 0.0, 2: 0.25, 5: 0.12, 1: 0.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.0, 0: 0.0, 5: 0.04, 4: 0.97, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0003 train_loss= 2.12767 train_acc= 0.16667 val_acc= 0.15837 val_auc= 0.61868 time= 1.96675\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.0, 6: 0.0, 2: 0.12, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.0, 0: 0.0, 5: 0.04, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0004 train_loss= 2.08546 train_acc= 0.18182 val_acc= 0.15385 val_auc= 0.62837 time= 2.31083\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.0, 6: 0.0, 2: 0.0, 5: 0.25, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.0, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0005 train_loss= 2.05234 train_acc= 0.22727 val_acc= 0.15385 val_auc= 0.63957 time= 2.65090\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.05, 6: 0.0, 2: 0.25, 5: 0.25, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.0, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0006 train_loss= 2.02769 train_acc= 0.21212 val_acc= 0.16290 val_auc= 0.65339 time= 2.98101\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.0, 6: 0.0, 2: 0.5, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.05, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0007 train_loss= 2.00756 train_acc= 0.21212 val_acc= 0.17195 val_auc= 0.66288 time= 3.31315\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.0, 6: 0.0, 2: 0.5, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.1, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0008 train_loss= 1.99800 train_acc= 0.21212 val_acc= 0.17195 val_auc= 0.67060 time= 3.64925\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.0, 6: 0.0, 2: 0.5, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.1, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0009 train_loss= 1.99142 train_acc= 0.25758 val_acc= 0.17195 val_auc= 0.67580 time= 3.99729\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.0, 6: 0.0, 2: 0.75, 5: 0.12, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.1, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0010 train_loss= 1.98207 train_acc= 0.24242 val_acc= 0.19457 val_auc= 0.67908 time= 4.32741\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.05, 6: 0.0, 2: 0.62, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.21, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0011 train_loss= 1.97791 train_acc= 0.21212 val_acc= 0.20814 val_auc= 0.68145 time= 4.68149\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.0, 6: 0.0, 2: 0.62, 5: 0.0, 1: 0.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.29, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0012 train_loss= 1.97591 train_acc= 0.27273 val_acc= 0.21267 val_auc= 0.68414 time= 5.03651\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.0, 6: 0.0, 2: 0.75, 5: 0.25, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.31, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0013 train_loss= 1.98174 train_acc= 0.27273 val_acc= 0.22624 val_auc= 0.68686 time= 5.37962\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.05, 6: 0.0, 2: 0.88, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.38, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0014 train_loss= 1.97974 train_acc= 0.28788 val_acc= 0.22624 val_auc= 0.68954 time= 5.74964\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.1, 6: 0.0, 2: 0.88, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.38, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0015 train_loss= 1.98311 train_acc= 0.24242 val_acc= 0.23982 val_auc= 0.69195 time= 6.09769\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.0, 6: 0.0, 2: 0.75, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.45, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0016 train_loss= 1.97886 train_acc= 0.27273 val_acc= 0.24887 val_auc= 0.69476 time= 6.44279\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.1, 6: 0.0, 2: 0.75, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.5, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0017 train_loss= 1.98336 train_acc= 0.27273 val_acc= 0.27602 val_auc= 0.69814 time= 6.79581\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.05, 6: 0.0, 2: 0.88, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.64, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0018 train_loss= 1.98273 train_acc= 0.27273 val_acc= 0.28054 val_auc= 0.70116 time= 7.15086\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.05, 6: 0.0, 2: 0.88, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.67, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0019 train_loss= 1.97893 train_acc= 0.27273 val_acc= 0.28507 val_auc= 0.70443 time= 7.51694\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.05, 6: 0.0, 2: 0.88, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.69, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0020 train_loss= 1.98229 train_acc= 0.28788 val_acc= 0.28507 val_auc= 0.70781 time= 7.86895\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.05, 6: 0.0, 2: 0.88, 5: 0.12, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.69, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0021 train_loss= 1.97762 train_acc= 0.31818 val_acc= 0.29412 val_auc= 0.71177 time= 8.22798\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.2, 6: 0.0, 2: 0.88, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.74, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0022 train_loss= 1.97201 train_acc= 0.36364 val_acc= 0.30769 val_auc= 0.71573 time= 8.60700\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.25, 6: 0.0, 2: 0.88, 5: 0.25, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.81, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0023 train_loss= 1.97625 train_acc= 0.30303 val_acc= 0.30769 val_auc= 0.72034 time= 8.95008\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.1, 6: 0.0, 2: 0.88, 5: 0.12, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.81, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0024 train_loss= 1.96948 train_acc= 0.31818 val_acc= 0.30769 val_auc= 0.72622 time= 9.28117\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.2, 6: 0.0, 2: 0.88, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.81, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0025 train_loss= 1.97155 train_acc= 0.33333 val_acc= 0.30769 val_auc= 0.73378 time= 9.61131\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.2, 6: 0.0, 2: 0.88, 5: 0.25, 1: 0.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.81, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0026 train_loss= 1.96169 train_acc= 0.31818 val_acc= 0.31222 val_auc= 0.74062 time= 9.95238\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.1, 6: 0.0, 2: 1.0, 5: 0.12, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.83, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0027 train_loss= 1.96552 train_acc= 0.28788 val_acc= 0.31222 val_auc= 0.74576 time= 10.30742\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.15, 6: 0.0, 2: 1.0, 5: 0.0, 1: 0.0, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.83, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0028 train_loss= 1.95931 train_acc= 0.28788 val_acc= 0.31222 val_auc= 0.74896 time= 10.66955\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.05, 6: 0.0, 2: 1.0, 5: 0.12, 1: 0.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.83, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0029 train_loss= 1.95711 train_acc= 0.34848 val_acc= 0.30769 val_auc= 0.75145 time= 11.03256\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.2, 6: 0.0, 2: 0.88, 5: 0.38, 1: 0.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.81, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0030 train_loss= 1.95730 train_acc= 0.33333 val_acc= 0.30769 val_auc= 0.75364 time= 11.38961\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.15, 6: 0.0, 2: 0.88, 5: 0.25, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.81, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0031 train_loss= 1.95312 train_acc= 0.31818 val_acc= 0.30769 val_auc= 0.75516 time= 11.77061\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.15, 6: 0.0, 2: 0.88, 5: 0.12, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.81, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0032 train_loss= 1.95249 train_acc= 0.36364 val_acc= 0.30769 val_auc= 0.75721 time= 12.15356\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.25, 6: 0.0, 2: 0.88, 5: 0.12, 1: 0.17, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.81, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0033 train_loss= 1.95181 train_acc= 0.28788 val_acc= 0.31222 val_auc= 0.76036 time= 12.53058\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.05, 6: 0.33, 2: 0.88, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.83, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0034 train_loss= 1.94780 train_acc= 0.34848 val_acc= 0.31674 val_auc= 0.76454 time= 12.91353\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.2, 6: 0.0, 2: 1.0, 5: 0.12, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.86, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0035 train_loss= 1.94371 train_acc= 0.34848 val_acc= 0.31674 val_auc= 0.76792 time= 13.27856\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.25, 6: 0.0, 2: 0.88, 5: 0.12, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.86, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0036 train_loss= 1.94425 train_acc= 0.31818 val_acc= 0.31674 val_auc= 0.77257 time= 13.66755\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.15, 6: 0.0, 2: 1.0, 5: 0.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.86, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0037 train_loss= 1.94363 train_acc= 0.34848 val_acc= 0.32127 val_auc= 0.77658 time= 14.07942\n",
      "train_accuracy_per_classes:{3: 0.09, 0: 0.15, 6: 0.0, 2: 1.0, 5: 0.12, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.88, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0038 train_loss= 1.94393 train_acc= 0.36364 val_acc= 0.33032 val_auc= 0.78208 time= 14.56711\n",
      "train_accuracy_per_classes:{3: 0.18, 0: 0.15, 6: 0.0, 2: 1.0, 5: 0.12, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.93, 0: 0.0, 5: 0.0, 4: 1.0, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0039 train_loss= 1.94046 train_acc= 0.31818 val_acc= 0.32579 val_auc= 0.78817 time= 14.94111\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.1, 6: 0.0, 2: 1.0, 5: 0.12, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.93, 0: 0.0, 5: 0.0, 4: 0.97, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0040 train_loss= 1.94050 train_acc= 0.34848 val_acc= 0.32127 val_auc= 0.79699 time= 15.30716\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.15, 6: 0.0, 2: 1.0, 5: 0.25, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.93, 0: 0.0, 5: 0.0, 4: 0.94, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0041 train_loss= 1.93752 train_acc= 0.39394 val_acc= 0.31674 val_auc= 0.80527 time= 15.69116\n",
      "train_accuracy_per_classes:{3: 0.09, 0: 0.2, 6: 0.0, 2: 1.0, 5: 0.5, 1: 0.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.95, 0: 0.0, 5: 0.0, 4: 0.88, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0042 train_loss= 1.93510 train_acc= 0.37879 val_acc= 0.31674 val_auc= 0.81274 time= 16.08007\n",
      "train_accuracy_per_classes:{3: 0.09, 0: 0.15, 6: 0.0, 2: 1.0, 5: 0.25, 1: 0.17, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.95, 0: 0.0, 5: 0.0, 4: 0.88, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0043 train_loss= 1.93697 train_acc= 0.39394 val_acc= 0.32579 val_auc= 0.82178 time= 16.44809\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.25, 6: 0.33, 2: 1.0, 5: 0.25, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.95, 0: 0.02, 5: 0.04, 4: 0.88, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0044 train_loss= 1.93417 train_acc= 0.39394 val_acc= 0.32579 val_auc= 0.83071 time= 16.80715\n",
      "train_accuracy_per_classes:{3: 0.18, 0: 0.2, 6: 0.0, 2: 1.0, 5: 0.25, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.95, 0: 0.02, 5: 0.04, 4: 0.88, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0045 train_loss= 1.93128 train_acc= 0.45455 val_acc= 0.35747 val_auc= 0.83933 time= 17.16719\n",
      "train_accuracy_per_classes:{3: 0.09, 0: 0.25, 6: 0.33, 2: 1.0, 5: 0.62, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.95, 0: 0.05, 5: 0.16, 4: 0.94, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0046 train_loss= 1.93222 train_acc= 0.45455 val_acc= 0.37557 val_auc= 0.84823 time= 17.53120\n",
      "train_accuracy_per_classes:{3: 0.0, 0: 0.25, 6: 0.33, 2: 1.0, 5: 0.5, 1: 0.33, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.95, 0: 0.09, 5: 0.2, 4: 0.97, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0047 train_loss= 1.93202 train_acc= 0.53030 val_acc= 0.39819 val_auc= 0.85716 time= 17.87231\n",
      "train_accuracy_per_classes:{3: 0.18, 0: 0.3, 6: 0.33, 2: 1.0, 5: 0.88, 1: 0.17, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.95, 0: 0.09, 5: 0.4, 4: 0.97, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0048 train_loss= 1.92545 train_acc= 0.48485 val_acc= 0.40272 val_auc= 0.86504 time= 18.21337\n",
      "train_accuracy_per_classes:{3: 0.09, 0: 0.3, 6: 0.33, 2: 1.0, 5: 0.75, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.98, 0: 0.09, 5: 0.4, 4: 0.97, 3: 0.0, 6: 0.0}\n",
      "Epoch: 0049 train_loss= 1.93033 train_acc= 0.54545 val_acc= 0.41629 val_auc= 0.87161 time= 18.55445\n",
      "train_accuracy_per_classes:{3: 0.18, 0: 0.35, 6: 0.33, 2: 1.0, 5: 0.88, 1: 0.17, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.98, 0: 0.1, 5: 0.44, 4: 0.94, 3: 0.05, 6: 0.06}\n",
      "Epoch: 0050 train_loss= 1.92214 train_acc= 0.54545 val_acc= 0.42986 val_auc= 0.87734 time= 18.89059\n",
      "train_accuracy_per_classes:{3: 0.27, 0: 0.35, 6: 0.33, 2: 1.0, 5: 0.75, 1: 0.17, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 1.0, 0: 0.1, 5: 0.52, 4: 0.94, 3: 0.05, 6: 0.06}\n",
      "Epoch: 0051 train_loss= 1.92365 train_acc= 0.65152 val_acc= 0.46154 val_auc= 0.88332 time= 19.23164\n",
      "train_accuracy_per_classes:{3: 0.55, 0: 0.45, 6: 0.67, 2: 1.0, 5: 0.88, 1: 0.17, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 1.0, 0: 0.14, 5: 0.72, 4: 0.94, 3: 0.05, 6: 0.06}\n",
      "Epoch: 0052 train_loss= 1.91932 train_acc= 0.63636 val_acc= 0.46606 val_auc= 0.88888 time= 19.57476\n",
      "train_accuracy_per_classes:{3: 0.55, 0: 0.45, 6: 0.33, 2: 1.0, 5: 0.88, 1: 0.17, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.98, 0: 0.19, 5: 0.72, 4: 0.91, 3: 0.05, 6: 0.06}\n",
      "Epoch: 0053 train_loss= 1.91696 train_acc= 0.65152 val_acc= 0.46606 val_auc= 0.89338 time= 19.92080\n",
      "train_accuracy_per_classes:{3: 0.45, 0: 0.6, 6: 0.33, 2: 1.0, 5: 0.88, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.95, 0: 0.19, 5: 0.72, 4: 0.91, 3: 0.1, 6: 0.06}\n",
      "Epoch: 0054 train_loss= 1.92003 train_acc= 0.63636 val_acc= 0.48416 val_auc= 0.89740 time= 20.26388\n",
      "train_accuracy_per_classes:{3: 0.27, 0: 0.6, 6: 0.33, 2: 1.0, 5: 0.75, 1: 0.33, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.0, 2: 0.95, 0: 0.26, 5: 0.72, 4: 0.91, 3: 0.1, 6: 0.06}\n",
      "Epoch: 0055 train_loss= 1.91841 train_acc= 0.69697 val_acc= 0.50679 val_auc= 0.90074 time= 20.61594\n",
      "train_accuracy_per_classes:{3: 0.45, 0: 0.75, 6: 0.33, 2: 1.0, 5: 0.88, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.04, 2: 0.95, 0: 0.31, 5: 0.76, 4: 0.91, 3: 0.1, 6: 0.06}\n",
      "Epoch: 0056 train_loss= 1.91410 train_acc= 0.74242 val_acc= 0.52036 val_auc= 0.90417 time= 20.96002\n",
      "train_accuracy_per_classes:{3: 0.73, 0: 0.6, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.17, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.04, 2: 0.95, 0: 0.34, 5: 0.76, 4: 0.91, 3: 0.14, 6: 0.06}\n",
      "Epoch: 0057 train_loss= 1.91228 train_acc= 0.77273 val_acc= 0.52941 val_auc= 0.90624 time= 21.30410\n",
      "train_accuracy_per_classes:{3: 0.73, 0: 0.6, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.5, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.04, 2: 0.95, 0: 0.34, 5: 0.76, 4: 0.91, 3: 0.19, 6: 0.11}\n",
      "Epoch: 0058 train_loss= 1.91359 train_acc= 0.74242 val_acc= 0.53846 val_auc= 0.90788 time= 21.64522\n",
      "train_accuracy_per_classes:{3: 0.73, 0: 0.65, 6: 0.33, 2: 1.0, 5: 0.88, 1: 0.33, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.04, 2: 0.95, 0: 0.36, 5: 0.76, 4: 0.91, 3: 0.19, 6: 0.17}\n",
      "Epoch: 0059 train_loss= 1.91526 train_acc= 0.80303 val_acc= 0.55656 val_auc= 0.91072 time= 21.98927\n",
      "train_accuracy_per_classes:{3: 0.82, 0: 0.85, 6: 0.67, 2: 1.0, 5: 0.88, 1: 0.17, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.04, 2: 0.95, 0: 0.4, 5: 0.76, 4: 0.91, 3: 0.29, 6: 0.17}\n",
      "Epoch: 0060 train_loss= 1.91175 train_acc= 0.75758 val_acc= 0.58371 val_auc= 0.91397 time= 22.33537\n",
      "train_accuracy_per_classes:{3: 0.73, 0: 0.75, 6: 0.33, 2: 1.0, 5: 1.0, 1: 0.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.04, 2: 0.95, 0: 0.47, 5: 0.76, 4: 0.91, 3: 0.38, 6: 0.17}\n",
      "Epoch: 0061 train_loss= 1.91339 train_acc= 0.81818 val_acc= 0.59729 val_auc= 0.91647 time= 22.67746\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.75, 6: 0.67, 2: 1.0, 5: 0.88, 1: 0.33, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.04, 2: 0.95, 0: 0.48, 5: 0.76, 4: 0.91, 3: 0.48, 6: 0.17}\n",
      "Epoch: 0062 train_loss= 1.90453 train_acc= 0.86364 val_acc= 0.59276 val_auc= 0.91769 time= 23.02054\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.8, 6: 0.33, 2: 1.0, 5: 1.0, 1: 0.5, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.04, 2: 0.95, 0: 0.48, 5: 0.76, 4: 0.91, 3: 0.48, 6: 0.11}\n",
      "Epoch: 0063 train_loss= 1.90986 train_acc= 0.87879 val_acc= 0.58824 val_auc= 0.91770 time= 23.36961\n",
      "train_accuracy_per_classes:{3: 0.82, 0: 0.9, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.5, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.04, 2: 0.95, 0: 0.48, 5: 0.76, 4: 0.91, 3: 0.48, 6: 0.06}\n",
      "Epoch: 0064 train_loss= 1.90696 train_acc= 0.86364 val_acc= 0.60181 val_auc= 0.91775 time= 23.72064\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.85, 6: 0.33, 2: 1.0, 5: 1.0, 1: 0.33, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.04, 2: 0.95, 0: 0.52, 5: 0.76, 4: 0.91, 3: 0.52, 6: 0.06}\n",
      "Epoch: 0065 train_loss= 1.90237 train_acc= 0.84848 val_acc= 0.60181 val_auc= 0.91752 time= 24.06771\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.75, 6: 0.67, 2: 0.88, 5: 1.0, 1: 0.5, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.04, 2: 0.95, 0: 0.53, 5: 0.76, 4: 0.91, 3: 0.48, 6: 0.06}\n",
      "Epoch: 0066 train_loss= 1.90383 train_acc= 0.84848 val_acc= 0.60633 val_auc= 0.91854 time= 24.40581\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 0.75, 6: 0.67, 2: 0.88, 5: 1.0, 1: 0.67, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.09, 2: 0.95, 0: 0.53, 5: 0.76, 4: 0.91, 3: 0.48, 6: 0.06}\n",
      "Epoch: 0067 train_loss= 1.90415 train_acc= 0.77273 val_acc= 0.61991 val_auc= 0.91947 time= 24.74493\n",
      "train_accuracy_per_classes:{3: 0.82, 0: 0.8, 6: 0.33, 2: 0.88, 5: 0.75, 1: 0.33, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.17, 2: 0.95, 0: 0.57, 5: 0.76, 4: 0.91, 3: 0.43, 6: 0.06}\n",
      "Epoch: 0068 train_loss= 1.90078 train_acc= 0.92424 val_acc= 0.62896 val_auc= 0.91862 time= 25.09098\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.85, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.17, 2: 0.95, 0: 0.6, 5: 0.76, 4: 0.91, 3: 0.43, 6: 0.06}\n",
      "Epoch: 0069 train_loss= 1.90362 train_acc= 0.87879 val_acc= 0.62896 val_auc= 0.91780 time= 25.43506\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 0.85, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.67, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.17, 2: 0.95, 0: 0.6, 5: 0.76, 4: 0.91, 3: 0.48, 6: 0.0}\n",
      "Epoch: 0070 train_loss= 1.89950 train_acc= 0.90909 val_acc= 0.62896 val_auc= 0.91608 time= 25.77415\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 0.67, 2: 0.88, 5: 1.0, 1: 0.67, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.17, 2: 0.95, 0: 0.6, 5: 0.72, 4: 0.91, 3: 0.52, 6: 0.0}\n",
      "Epoch: 0071 train_loss= 1.89571 train_acc= 0.89394 val_acc= 0.63348 val_auc= 0.91639 time= 26.11126\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.75, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.17, 2: 0.95, 0: 0.62, 5: 0.72, 4: 0.91, 3: 0.52, 6: 0.0}\n",
      "Epoch: 0072 train_loss= 1.90119 train_acc= 0.89394 val_acc= 0.64253 val_auc= 0.91730 time= 26.45635\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 0.9, 6: 0.67, 2: 1.0, 5: 0.88, 1: 0.67, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.22, 2: 0.95, 0: 0.62, 5: 0.72, 4: 0.91, 3: 0.57, 6: 0.0}\n",
      "Epoch: 0073 train_loss= 1.89694 train_acc= 0.87879 val_acc= 0.65158 val_auc= 0.91867 time= 26.79944\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.85, 6: 0.67, 2: 0.88, 5: 1.0, 1: 0.5, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.22, 2: 0.95, 0: 0.64, 5: 0.76, 4: 0.91, 3: 0.57, 6: 0.0}\n",
      "Epoch: 0074 train_loss= 1.89676 train_acc= 0.86364 val_acc= 0.65611 val_auc= 0.91964 time= 27.13654\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.85, 6: 0.33, 2: 1.0, 5: 1.0, 1: 0.33, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.26, 2: 0.95, 0: 0.64, 5: 0.76, 4: 0.91, 3: 0.57, 6: 0.0}\n",
      "Epoch: 0075 train_loss= 1.89466 train_acc= 0.89394 val_acc= 0.65611 val_auc= 0.92128 time= 27.47561\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 0.67, 2: 0.88, 5: 0.88, 1: 0.67, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.26, 2: 0.95, 0: 0.64, 5: 0.76, 4: 0.88, 3: 0.57, 6: 0.06}\n",
      "Epoch: 0076 train_loss= 1.89472 train_acc= 0.90909 val_acc= 0.65158 val_auc= 0.92208 time= 27.81573\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 0.67, 2: 0.88, 5: 1.0, 1: 0.67, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.26, 2: 0.93, 0: 0.64, 5: 0.76, 4: 0.88, 3: 0.57, 6: 0.06}\n",
      "Epoch: 0077 train_loss= 1.89713 train_acc= 0.92424 val_acc= 0.66063 val_auc= 0.92165 time= 28.17676\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 0.88, 5: 1.0, 1: 0.67, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.26, 2: 0.93, 0: 0.66, 5: 0.76, 4: 0.88, 3: 0.62, 6: 0.06}\n",
      "Epoch: 0078 train_loss= 1.89743 train_acc= 0.87879 val_acc= 0.66516 val_auc= 0.92121 time= 28.55173\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.85, 6: 0.67, 2: 0.88, 5: 1.0, 1: 0.67, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.3, 2: 0.93, 0: 0.66, 5: 0.76, 4: 0.88, 3: 0.62, 6: 0.06}\n",
      "Epoch: 0079 train_loss= 1.89286 train_acc= 0.92424 val_acc= 0.68326 val_auc= 0.92241 time= 28.89783\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.67, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.35, 2: 0.9, 0: 0.71, 5: 0.76, 4: 0.88, 3: 0.67, 6: 0.06}\n",
      "Epoch: 0080 train_loss= 1.89668 train_acc= 0.92424 val_acc= 0.70588 val_auc= 0.92298 time= 29.24989\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.67, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.43, 2: 0.9, 0: 0.76, 5: 0.76, 4: 0.88, 3: 0.67, 6: 0.06}\n",
      "Epoch: 0081 train_loss= 1.89445 train_acc= 0.89394 val_acc= 0.70588 val_auc= 0.92330 time= 29.60791\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 0.9, 6: 0.33, 2: 0.88, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.43, 2: 0.9, 0: 0.76, 5: 0.76, 4: 0.88, 3: 0.67, 6: 0.06}\n",
      "Epoch: 0082 train_loss= 1.89144 train_acc= 0.93939 val_acc= 0.70136 val_auc= 0.92298 time= 29.95399\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.43, 2: 0.9, 0: 0.76, 5: 0.76, 4: 0.88, 3: 0.67, 6: 0.0}\n",
      "Epoch: 0083 train_loss= 1.89254 train_acc= 0.87879 val_acc= 0.70136 val_auc= 0.92221 time= 30.31802\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.85, 6: 0.67, 2: 1.0, 5: 0.88, 1: 0.67, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.43, 2: 0.9, 0: 0.76, 5: 0.76, 4: 0.88, 3: 0.67, 6: 0.0}\n",
      "Epoch: 0084 train_loss= 1.88526 train_acc= 0.92424 val_acc= 0.70588 val_auc= 0.92198 time= 30.70996\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.33, 2: 1.0, 5: 1.0, 1: 0.67, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.43, 2: 0.93, 0: 0.76, 5: 0.76, 4: 0.88, 3: 0.67, 6: 0.0}\n",
      "Epoch: 0085 train_loss= 1.89033 train_acc= 0.87879 val_acc= 0.70588 val_auc= 0.92161 time= 31.09991\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 0.9, 6: 0.67, 2: 1.0, 5: 0.88, 1: 0.5, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.43, 2: 0.93, 0: 0.76, 5: 0.76, 4: 0.88, 3: 0.67, 6: 0.0}\n",
      "Epoch: 0086 train_loss= 1.89510 train_acc= 0.93939 val_acc= 0.70588 val_auc= 0.92052 time= 31.45995\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.43, 2: 0.93, 0: 0.76, 5: 0.72, 4: 0.88, 3: 0.71, 6: 0.0}\n",
      "Epoch: 0087 train_loss= 1.88962 train_acc= 0.92424 val_acc= 0.71041 val_auc= 0.92123 time= 31.81905\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 0.88, 1: 0.83, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.43, 2: 0.93, 0: 0.76, 5: 0.76, 4: 0.88, 3: 0.71, 6: 0.0}\n",
      "Epoch: 0088 train_loss= 1.88429 train_acc= 0.92424 val_acc= 0.71946 val_auc= 0.92461 time= 32.19798\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.67, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.9, 0: 0.79, 5: 0.76, 4: 0.85, 3: 0.67, 6: 0.0}\n",
      "Epoch: 0089 train_loss= 1.88891 train_acc= 0.90909 val_acc= 0.73303 val_auc= 0.92747 time= 32.56101\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 0.67, 2: 1.0, 5: 0.88, 1: 0.67, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.9, 0: 0.83, 5: 0.8, 4: 0.85, 3: 0.62, 6: 0.06}\n",
      "Epoch: 0090 train_loss= 1.89149 train_acc= 0.93939 val_acc= 0.73303 val_auc= 0.92953 time= 32.90711\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 0.33, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.9, 0: 0.81, 5: 0.8, 4: 0.85, 3: 0.67, 6: 0.06}\n",
      "Epoch: 0091 train_loss= 1.88827 train_acc= 0.90909 val_acc= 0.72851 val_auc= 0.93029 time= 33.25318\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.85, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.83, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.9, 0: 0.81, 5: 0.8, 4: 0.82, 3: 0.67, 6: 0.06}\n",
      "Epoch: 0092 train_loss= 1.88715 train_acc= 0.93939 val_acc= 0.74208 val_auc= 0.92929 time= 33.59624\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 0.88, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.9, 0: 0.83, 5: 0.8, 4: 0.82, 3: 0.71, 6: 0.11}\n",
      "Epoch: 0093 train_loss= 1.88673 train_acc= 0.92424 val_acc= 0.73303 val_auc= 0.92576 time= 33.95232\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 1.0, 2: 1.0, 5: 0.75, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.52, 2: 0.9, 0: 0.78, 5: 0.8, 4: 0.82, 3: 0.81, 6: 0.11}\n",
      "Epoch: 0094 train_loss= 1.88634 train_acc= 0.95455 val_acc= 0.72398 val_auc= 0.92453 time= 34.30437\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.43, 2: 0.9, 0: 0.78, 5: 0.76, 4: 0.82, 3: 0.81, 6: 0.17}\n",
      "Epoch: 0095 train_loss= 1.88512 train_acc= 0.93939 val_acc= 0.74208 val_auc= 0.92535 time= 34.64846\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.52, 2: 0.9, 0: 0.83, 5: 0.76, 4: 0.82, 3: 0.81, 6: 0.11}\n",
      "Epoch: 0096 train_loss= 1.88920 train_acc= 0.92424 val_acc= 0.74661 val_auc= 0.92749 time= 34.99849\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.67, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.88, 0: 0.83, 5: 0.8, 4: 0.82, 3: 0.81, 6: 0.11}\n",
      "Epoch: 0097 train_loss= 1.88615 train_acc= 0.92424 val_acc= 0.72851 val_auc= 0.92901 time= 35.35058\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 0.88, 1: 0.67, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.86, 0: 0.86, 5: 0.8, 4: 0.82, 3: 0.62, 6: 0.06}\n",
      "Epoch: 0098 train_loss= 1.88169 train_acc= 0.96970 val_acc= 0.72851 val_auc= 0.92827 time= 35.70363\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.83, 0: 0.88, 5: 0.8, 4: 0.82, 3: 0.62, 6: 0.06}\n",
      "Epoch: 0099 train_loss= 1.89273 train_acc= 0.90909 val_acc= 0.73303 val_auc= 0.92709 time= 36.04971\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.67, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.83, 0: 0.88, 5: 0.8, 4: 0.82, 3: 0.71, 6: 0.0}\n",
      "Epoch: 0100 train_loss= 1.88558 train_acc= 0.95455 val_acc= 0.74208 val_auc= 0.92441 time= 36.39675\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.88, 0: 0.84, 5: 0.8, 4: 0.82, 3: 0.81, 6: 0.0}\n",
      "Epoch: 0101 train_loss= 1.88552 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.92120 time= 36.74286\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.88, 0: 0.84, 5: 0.76, 4: 0.82, 3: 0.86, 6: 0.0}\n",
      "Epoch: 0102 train_loss= 1.87671 train_acc= 0.95455 val_acc= 0.73303 val_auc= 0.92032 time= 37.09289\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 0.88, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.86, 0: 0.83, 5: 0.76, 4: 0.82, 3: 0.86, 6: 0.0}\n",
      "Epoch: 0103 train_loss= 1.87817 train_acc= 0.92424 val_acc= 0.73756 val_auc= 0.92313 time= 37.43997\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 0.88, 5: 0.88, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.86, 0: 0.84, 5: 0.76, 4: 0.82, 3: 0.86, 6: 0.0}\n",
      "Epoch: 0104 train_loss= 1.87844 train_acc= 0.93939 val_acc= 0.73756 val_auc= 0.92590 time= 37.79901\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.67, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.86, 0: 0.84, 5: 0.8, 4: 0.82, 3: 0.81, 6: 0.0}\n",
      "Epoch: 0105 train_loss= 1.88158 train_acc= 0.95455 val_acc= 0.73756 val_auc= 0.92796 time= 38.15309\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.61, 2: 0.83, 0: 0.88, 5: 0.8, 4: 0.82, 3: 0.71, 6: 0.0}\n",
      "Epoch: 0106 train_loss= 1.88051 train_acc= 0.96970 val_acc= 0.73303 val_auc= 0.92806 time= 38.51710\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.65, 2: 0.83, 0: 0.88, 5: 0.8, 4: 0.79, 3: 0.67, 6: 0.0}\n",
      "Epoch: 0107 train_loss= 1.87791 train_acc= 0.96970 val_acc= 0.73303 val_auc= 0.92817 time= 38.86715\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.7, 2: 0.83, 0: 0.88, 5: 0.8, 4: 0.79, 3: 0.62, 6: 0.0}\n",
      "Epoch: 0108 train_loss= 1.88032 train_acc= 0.95455 val_acc= 0.73756 val_auc= 0.92791 time= 39.22123\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.33, 2: 1.0, 5: 0.88, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.74, 2: 0.81, 0: 0.88, 5: 0.8, 4: 0.79, 3: 0.67, 6: 0.0}\n",
      "Epoch: 0109 train_loss= 1.88623 train_acc= 0.93939 val_acc= 0.74661 val_auc= 0.92700 time= 39.56529\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 0.88, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.7, 2: 0.81, 0: 0.88, 5: 0.8, 4: 0.79, 3: 0.81, 6: 0.0}\n",
      "Epoch: 0110 train_loss= 1.88370 train_acc= 0.95455 val_acc= 0.72851 val_auc= 0.92433 time= 39.91734\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.79, 0: 0.86, 5: 0.8, 4: 0.79, 3: 0.86, 6: 0.0}\n",
      "Epoch: 0111 train_loss= 1.87591 train_acc= 0.95455 val_acc= 0.73303 val_auc= 0.92389 time= 40.27342\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.79, 0: 0.88, 5: 0.8, 4: 0.79, 3: 0.86, 6: 0.0}\n",
      "Epoch: 0112 train_loss= 1.87563 train_acc= 0.92424 val_acc= 0.72851 val_auc= 0.92545 time= 40.62345\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 0.67, 2: 1.0, 5: 0.88, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.57, 2: 0.79, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.86, 6: 0.0}\n",
      "Epoch: 0113 train_loss= 1.87411 train_acc= 0.95455 val_acc= 0.73303 val_auc= 0.92770 time= 40.97153\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.7, 2: 0.79, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.76, 6: 0.0}\n",
      "Epoch: 0114 train_loss= 1.87786 train_acc= 0.96970 val_acc= 0.73303 val_auc= 0.92943 time= 41.32162\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.33, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.74, 2: 0.79, 0: 0.88, 5: 0.8, 4: 0.79, 3: 0.67, 6: 0.0}\n",
      "Epoch: 0115 train_loss= 1.87432 train_acc= 0.93939 val_acc= 0.73303 val_auc= 0.93045 time= 41.77837\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.74, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.79, 3: 0.71, 6: 0.0}\n",
      "Epoch: 0116 train_loss= 1.87675 train_acc= 0.96970 val_acc= 0.73756 val_auc= 0.93059 time= 42.12344\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.74, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.79, 3: 0.71, 6: 0.06}\n",
      "Epoch: 0117 train_loss= 1.87566 train_acc= 0.92424 val_acc= 0.74208 val_auc= 0.93035 time= 42.47550\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 0.67, 2: 0.88, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.7, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.79, 3: 0.81, 6: 0.06}\n",
      "Epoch: 0118 train_loss= 1.87724 train_acc= 0.96970 val_acc= 0.73756 val_auc= 0.92955 time= 42.82260\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.61, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.86, 6: 0.11}\n",
      "Epoch: 0119 train_loss= 1.88208 train_acc= 0.93939 val_acc= 0.74208 val_auc= 0.92883 time= 43.17064\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 0.88, 5: 0.88, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.65, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.86, 6: 0.11}\n",
      "Epoch: 0120 train_loss= 1.87680 train_acc= 0.89394 val_acc= 0.75113 val_auc= 0.92801 time= 43.51871\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.33, 2: 0.88, 5: 0.88, 1: 0.83, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.78, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.86, 6: 0.06}\n",
      "Epoch: 0121 train_loss= 1.87920 train_acc= 0.90909 val_acc= 0.74208 val_auc= 0.92856 time= 43.86479\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.33, 2: 0.75, 5: 1.0, 1: 1.0, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.74, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.76, 6: 0.06}\n",
      "Epoch: 0122 train_loss= 1.87791 train_acc= 0.98485 val_acc= 0.73756 val_auc= 0.92824 time= 44.21588\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.71, 6: 0.0}\n",
      "Epoch: 0123 train_loss= 1.87529 train_acc= 0.96970 val_acc= 0.73303 val_auc= 0.92733 time= 44.57691\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.33, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.76, 0: 0.9, 5: 0.8, 4: 0.76, 3: 0.62, 6: 0.0}\n",
      "Epoch: 0124 train_loss= 1.87618 train_acc= 0.93939 val_acc= 0.73303 val_auc= 0.92749 time= 44.92695\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.78, 2: 0.76, 0: 0.9, 5: 0.8, 4: 0.76, 3: 0.67, 6: 0.0}\n",
      "Epoch: 0125 train_loss= 1.87789 train_acc= 0.96970 val_acc= 0.72851 val_auc= 0.92762 time= 45.28003\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.74, 2: 0.74, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.76, 6: 0.0}\n",
      "Epoch: 0126 train_loss= 1.87081 train_acc= 0.95455 val_acc= 0.74208 val_auc= 0.92670 time= 45.63306\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.33, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.74, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.79, 3: 0.81, 6: 0.0}\n",
      "Epoch: 0127 train_loss= 1.87527 train_acc= 0.98485 val_acc= 0.73303 val_auc= 0.92649 time= 45.99113\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.65, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.79, 3: 0.81, 6: 0.0}\n",
      "Epoch: 0128 train_loss= 1.86945 train_acc= 0.98485 val_acc= 0.72398 val_auc= 0.92688 time= 46.37012\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.61, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.81, 6: 0.0}\n",
      "Epoch: 0129 train_loss= 1.87532 train_acc= 0.96970 val_acc= 0.71946 val_auc= 0.92864 time= 46.73016\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.65, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.71, 6: 0.0}\n",
      "Epoch: 0130 train_loss= 1.87242 train_acc= 0.98485 val_acc= 0.72398 val_auc= 0.92997 time= 47.10812\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.7, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.67, 6: 0.06}\n",
      "Epoch: 0131 train_loss= 1.87540 train_acc= 0.93939 val_acc= 0.72398 val_auc= 0.93048 time= 47.49109\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 0.75, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.74, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.62, 6: 0.06}\n",
      "Epoch: 0132 train_loss= 1.87075 train_acc= 0.96970 val_acc= 0.73303 val_auc= 0.93076 time= 47.87507\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.78, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.67, 6: 0.06}\n",
      "Epoch: 0133 train_loss= 1.87441 train_acc= 0.95455 val_acc= 0.74661 val_auc= 0.93032 time= 48.24110\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 1.0, 5: 0.75, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.71, 6: 0.06}\n",
      "Epoch: 0134 train_loss= 1.86737 train_acc= 0.98485 val_acc= 0.75113 val_auc= 0.92990 time= 48.64004\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.71, 6: 0.11}\n",
      "Epoch: 0135 train_loss= 1.87346 train_acc= 0.96970 val_acc= 0.74661 val_auc= 0.92928 time= 49.00809\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 0.88, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.71, 6: 0.06}\n",
      "Epoch: 0136 train_loss= 1.86963 train_acc= 0.95455 val_acc= 0.75113 val_auc= 0.92837 time= 49.39004\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.76, 6: 0.06}\n",
      "Epoch: 0137 train_loss= 1.86614 train_acc= 0.98485 val_acc= 0.74661 val_auc= 0.92836 time= 49.78000\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.76, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.71, 6: 0.06}\n",
      "Epoch: 0138 train_loss= 1.86592 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.92858 time= 50.16597\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 0.88, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.76, 0: 0.9, 5: 0.8, 4: 0.76, 3: 0.67, 6: 0.0}\n",
      "Epoch: 0139 train_loss= 1.86936 train_acc= 0.96970 val_acc= 0.75113 val_auc= 0.92882 time= 50.54894\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 0.95, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.76, 0: 0.91, 5: 0.8, 4: 0.76, 3: 0.67, 6: 0.06}\n",
      "Epoch: 0140 train_loss= 1.87233 train_acc= 0.95455 val_acc= 0.74661 val_auc= 0.92939 time= 50.95386\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.75, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.74, 0: 0.91, 5: 0.8, 4: 0.76, 3: 0.67, 6: 0.06}\n",
      "Epoch: 0141 train_loss= 1.87077 train_acc= 0.96970 val_acc= 0.74661 val_auc= 0.92972 time= 51.36578\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.74, 0: 0.91, 5: 0.8, 4: 0.76, 3: 0.67, 6: 0.06}\n",
      "Epoch: 0142 train_loss= 1.87211 train_acc= 0.92424 val_acc= 0.73756 val_auc= 0.92944 time= 51.77666\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.76, 3: 0.67, 6: 0.11}\n",
      "Epoch: 0143 train_loss= 1.87119 train_acc= 0.96970 val_acc= 0.74208 val_auc= 0.92919 time= 52.18756\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.76, 3: 0.71, 6: 0.11}\n",
      "Epoch: 0144 train_loss= 1.86778 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.92940 time= 52.59846\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.69, 0: 0.91, 5: 0.8, 4: 0.76, 3: 0.71, 6: 0.11}\n",
      "Epoch: 0145 train_loss= 1.86426 train_acc= 0.95455 val_acc= 0.73756 val_auc= 0.93013 time= 52.99141\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.69, 0: 0.91, 5: 0.8, 4: 0.76, 3: 0.67, 6: 0.11}\n",
      "Epoch: 0146 train_loss= 1.86667 train_acc= 0.96970 val_acc= 0.75566 val_auc= 0.93055 time= 53.38539\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.74, 0: 0.95, 5: 0.8, 4: 0.74, 3: 0.67, 6: 0.11}\n",
      "Epoch: 0147 train_loss= 1.86757 train_acc= 0.98485 val_acc= 0.74661 val_auc= 0.93028 time= 53.74939\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.74, 0: 0.95, 5: 0.8, 4: 0.74, 3: 0.62, 6: 0.06}\n",
      "Epoch: 0148 train_loss= 1.86663 train_acc= 0.93939 val_acc= 0.73756 val_auc= 0.93034 time= 54.11441\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.75, 5: 0.88, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.74, 0: 0.91, 5: 0.8, 4: 0.74, 3: 0.62, 6: 0.06}\n",
      "Epoch: 0149 train_loss= 1.86817 train_acc= 0.95455 val_acc= 0.75113 val_auc= 0.92951 time= 54.47744\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.74, 0: 0.91, 5: 0.8, 4: 0.76, 3: 0.71, 6: 0.06}\n",
      "Epoch: 0150 train_loss= 1.86716 train_acc= 0.95455 val_acc= 0.74208 val_auc= 0.92799 time= 54.87936\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.81, 6: 0.06}\n",
      "Epoch: 0151 train_loss= 1.86633 train_acc= 0.93939 val_acc= 0.74208 val_auc= 0.92667 time= 55.24143\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.88, 5: 0.76, 4: 0.76, 3: 0.86, 6: 0.06}\n",
      "Epoch: 0152 train_loss= 1.86641 train_acc= 0.95455 val_acc= 0.74661 val_auc= 0.92679 time= 55.62145\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.9, 5: 0.76, 4: 0.76, 3: 0.86, 6: 0.06}\n",
      "Epoch: 0153 train_loss= 1.86489 train_acc= 0.96970 val_acc= 0.74661 val_auc= 0.92840 time= 56.01832\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.67, 0: 0.91, 5: 0.8, 4: 0.76, 3: 0.81, 6: 0.06}\n",
      "Epoch: 0154 train_loss= 1.86616 train_acc= 0.96970 val_acc= 0.74208 val_auc= 0.92969 time= 56.39234\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.67, 0: 0.91, 5: 0.8, 4: 0.76, 3: 0.76, 6: 0.06}\n",
      "Epoch: 0155 train_loss= 1.86946 train_acc= 0.96970 val_acc= 0.75113 val_auc= 0.93098 time= 56.80325\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.9, 5: 0.8, 4: 0.76, 3: 0.76, 6: 0.11}\n",
      "Epoch: 0156 train_loss= 1.86651 train_acc= 0.96970 val_acc= 0.76471 val_auc= 0.93187 time= 57.19717\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.74, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.81, 6: 0.17}\n",
      "Epoch: 0157 train_loss= 1.86063 train_acc= 0.96970 val_acc= 0.76923 val_auc= 0.93190 time= 57.59111\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.74, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.81, 6: 0.22}\n",
      "Epoch: 0158 train_loss= 1.87136 train_acc= 0.95455 val_acc= 0.77376 val_auc= 0.93146 time= 57.98908\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.74, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0159 train_loss= 1.86961 train_acc= 0.96970 val_acc= 0.76923 val_auc= 0.93174 time= 58.38599\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.74, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.81, 6: 0.22}\n",
      "Epoch: 0160 train_loss= 1.86763 train_acc= 1.00000 val_acc= 0.74208 val_auc= 0.93196 time= 58.78991\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.74, 3: 0.67, 6: 0.22}\n",
      "Epoch: 0161 train_loss= 1.86333 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.93118 time= 59.18286\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.67, 0: 0.97, 5: 0.8, 4: 0.74, 3: 0.62, 6: 0.17}\n",
      "Epoch: 0162 train_loss= 1.86985 train_acc= 0.98485 val_acc= 0.75113 val_auc= 0.93018 time= 59.59378\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.67, 0: 0.95, 5: 0.8, 4: 0.74, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0163 train_loss= 1.87003 train_acc= 0.96970 val_acc= 0.74661 val_auc= 0.92874 time= 59.96577\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.74, 3: 0.81, 6: 0.17}\n",
      "Epoch: 0164 train_loss= 1.86068 train_acc= 0.96970 val_acc= 0.75113 val_auc= 0.92885 time= 60.35675\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.76, 3: 0.81, 6: 0.17}\n",
      "Epoch: 0165 train_loss= 1.86353 train_acc= 0.96970 val_acc= 0.75113 val_auc= 0.93023 time= 60.75267\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.67, 0: 0.91, 5: 0.8, 4: 0.76, 3: 0.76, 6: 0.22}\n",
      "Epoch: 0166 train_loss= 1.86576 train_acc= 0.96970 val_acc= 0.73756 val_auc= 0.93125 time= 61.12669\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.67, 0: 0.95, 5: 0.8, 4: 0.76, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0167 train_loss= 1.86551 train_acc= 0.96970 val_acc= 0.73303 val_auc= 0.93156 time= 61.51463\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.67, 0: 0.93, 5: 0.8, 4: 0.74, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0168 train_loss= 1.85487 train_acc= 0.96970 val_acc= 0.74208 val_auc= 0.93151 time= 61.92652\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.74, 3: 0.67, 6: 0.17}\n",
      "Epoch: 0169 train_loss= 1.85861 train_acc= 0.93939 val_acc= 0.75113 val_auc= 0.93151 time= 62.36535\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.33, 2: 0.88, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0170 train_loss= 1.85988 train_acc= 1.00000 val_acc= 0.76471 val_auc= 0.93083 time= 62.82213\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0171 train_loss= 1.86359 train_acc= 0.96970 val_acc= 0.76923 val_auc= 0.93019 time= 63.27293\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.76, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0172 train_loss= 1.86628 train_acc= 0.93939 val_acc= 0.75113 val_auc= 0.93086 time= 63.72671\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.71, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0173 train_loss= 1.86077 train_acc= 0.96970 val_acc= 0.76018 val_auc= 0.93062 time= 64.14659\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.75, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.71, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0174 train_loss= 1.86198 train_acc= 0.96970 val_acc= 0.76471 val_auc= 0.93124 time= 64.55387\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.71, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0175 train_loss= 1.85811 train_acc= 0.98485 val_acc= 0.77376 val_auc= 0.93156 time= 64.93184\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.76, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0176 train_loss= 1.86258 train_acc= 0.98485 val_acc= 0.75566 val_auc= 0.93254 time= 65.32677\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.71, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0177 train_loss= 1.86007 train_acc= 0.96970 val_acc= 0.75113 val_auc= 0.93371 time= 65.72072\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.71, 3: 0.67, 6: 0.28}\n",
      "Epoch: 0178 train_loss= 1.86035 train_acc= 0.96970 val_acc= 0.74208 val_auc= 0.93368 time= 66.11070\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.75, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.71, 3: 0.57, 6: 0.28}\n",
      "Epoch: 0179 train_loss= 1.85875 train_acc= 0.96970 val_acc= 0.74208 val_auc= 0.93388 time= 66.50462\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.71, 3: 0.57, 6: 0.28}\n",
      "Epoch: 0180 train_loss= 1.85239 train_acc= 0.95455 val_acc= 0.73756 val_auc= 0.93344 time= 66.90558\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.71, 3: 0.57, 6: 0.22}\n",
      "Epoch: 0181 train_loss= 1.85856 train_acc= 0.96970 val_acc= 0.74208 val_auc= 0.93374 time= 67.30748\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.74, 3: 0.57, 6: 0.22}\n",
      "Epoch: 0182 train_loss= 1.85981 train_acc= 0.98485 val_acc= 0.75113 val_auc= 0.93386 time= 67.69145\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.9, 5: 0.8, 4: 0.74, 3: 0.71, 6: 0.22}\n",
      "Epoch: 0183 train_loss= 1.85538 train_acc= 0.98485 val_acc= 0.75566 val_auc= 0.93321 time= 68.07742\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.9, 5: 0.8, 4: 0.74, 3: 0.76, 6: 0.22}\n",
      "Epoch: 0184 train_loss= 1.85011 train_acc= 1.00000 val_acc= 0.74661 val_auc= 0.93258 time= 68.45541\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.91, 5: 0.8, 4: 0.71, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0185 train_loss= 1.86211 train_acc= 0.98485 val_acc= 0.72851 val_auc= 0.93181 time= 68.87432\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.67, 0: 0.95, 5: 0.8, 4: 0.71, 3: 0.57, 6: 0.11}\n",
      "Epoch: 0186 train_loss= 1.85583 train_acc= 0.98485 val_acc= 0.73756 val_auc= 0.93180 time= 69.30617\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.67, 0: 0.93, 5: 0.8, 4: 0.71, 3: 0.71, 6: 0.11}\n",
      "Epoch: 0187 train_loss= 1.85864 train_acc= 0.96970 val_acc= 0.73303 val_auc= 0.93245 time= 69.69615\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.67, 0: 0.93, 5: 0.8, 4: 0.71, 3: 0.67, 6: 0.11}\n",
      "Epoch: 0188 train_loss= 1.86005 train_acc= 0.98485 val_acc= 0.74661 val_auc= 0.93326 time= 70.08608\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.91, 5: 0.8, 4: 0.74, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0189 train_loss= 1.85967 train_acc= 0.98485 val_acc= 0.73303 val_auc= 0.93368 time= 70.50000\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0190 train_loss= 1.85822 train_acc= 0.96970 val_acc= 0.74661 val_auc= 0.93432 time= 70.90091\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.71, 6: 0.22}\n",
      "Epoch: 0191 train_loss= 1.86647 train_acc= 0.96970 val_acc= 0.74208 val_auc= 0.93494 time= 71.29188\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0192 train_loss= 1.85965 train_acc= 0.98485 val_acc= 0.72398 val_auc= 0.93518 time= 71.68784\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.74, 3: 0.57, 6: 0.11}\n",
      "Epoch: 0193 train_loss= 1.85605 train_acc= 0.95455 val_acc= 0.71946 val_auc= 0.93488 time= 72.08975\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.75, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.57, 6: 0.11}\n",
      "Epoch: 0194 train_loss= 1.85907 train_acc= 0.96970 val_acc= 0.73756 val_auc= 0.93463 time= 72.50465\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.67, 6: 0.11}\n",
      "Epoch: 0195 train_loss= 1.85751 train_acc= 0.95455 val_acc= 0.74661 val_auc= 0.93427 time= 72.89458\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.75, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.76, 6: 0.11}\n",
      "Epoch: 0196 train_loss= 1.85548 train_acc= 0.98485 val_acc= 0.75113 val_auc= 0.93284 time= 73.28257\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0197 train_loss= 1.85386 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.93293 time= 73.65554\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.71, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0198 train_loss= 1.84683 train_acc= 0.96970 val_acc= 0.72398 val_auc= 0.93277 time= 74.06944\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.67, 0: 0.93, 5: 0.8, 4: 0.68, 3: 0.62, 6: 0.17}\n",
      "Epoch: 0199 train_loss= 1.85224 train_acc= 0.98485 val_acc= 0.72398 val_auc= 0.93224 time= 74.45045\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.64, 0: 0.97, 5: 0.8, 4: 0.68, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0200 train_loss= 1.84947 train_acc= 0.96970 val_acc= 0.72398 val_auc= 0.93260 time= 74.84337\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.67, 0: 0.95, 5: 0.8, 4: 0.68, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0201 train_loss= 1.85737 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.93396 time= 75.22538\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.67, 0: 0.93, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0202 train_loss= 1.86198 train_acc= 0.95455 val_acc= 0.75566 val_auc= 0.93406 time= 75.61631\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.71, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0203 train_loss= 1.85814 train_acc= 0.98485 val_acc= 0.75566 val_auc= 0.93379 time= 75.99929\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.74, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0204 train_loss= 1.85680 train_acc= 1.00000 val_acc= 0.75566 val_auc= 0.93331 time= 76.37331\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.91, 5: 0.8, 4: 0.76, 3: 0.71, 6: 0.22}\n",
      "Epoch: 0205 train_loss= 1.85616 train_acc= 0.98485 val_acc= 0.76018 val_auc= 0.93206 time= 76.74631\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.95, 5: 0.8, 4: 0.76, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0206 train_loss= 1.85171 train_acc= 0.96970 val_acc= 0.76923 val_auc= 0.93127 time= 77.12527\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.95, 5: 0.8, 4: 0.76, 3: 0.81, 6: 0.17}\n",
      "Epoch: 0207 train_loss= 1.84767 train_acc= 0.98485 val_acc= 0.76018 val_auc= 0.93181 time= 77.52420\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.95, 5: 0.8, 4: 0.74, 3: 0.81, 6: 0.11}\n",
      "Epoch: 0208 train_loss= 1.85211 train_acc= 0.96970 val_acc= 0.76923 val_auc= 0.93354 time= 77.94807\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.74, 3: 0.81, 6: 0.22}\n",
      "Epoch: 0209 train_loss= 1.86327 train_acc= 0.96970 val_acc= 0.76018 val_auc= 0.93601 time= 78.38291\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.91, 5: 0.8, 4: 0.71, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0210 train_loss= 1.85532 train_acc= 0.96970 val_acc= 0.74208 val_auc= 0.93798 time= 78.79582\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 0.88, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0211 train_loss= 1.85138 train_acc= 1.00000 val_acc= 0.73756 val_auc= 0.93954 time= 79.23064\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0212 train_loss= 1.85328 train_acc= 0.98485 val_acc= 0.73756 val_auc= 0.93956 time= 79.66049\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0213 train_loss= 1.85195 train_acc= 0.96970 val_acc= 0.73756 val_auc= 0.93903 time= 80.08639\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0214 train_loss= 1.85170 train_acc= 1.00000 val_acc= 0.74208 val_auc= 0.93780 time= 80.52718\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.86, 5: 0.8, 4: 0.71, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0215 train_loss= 1.85623 train_acc= 0.93939 val_acc= 0.74661 val_auc= 0.93543 time= 80.94207\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.85, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.71, 6: 0.22}\n",
      "Epoch: 0216 train_loss= 1.85938 train_acc= 0.96970 val_acc= 0.75566 val_auc= 0.93265 time= 81.35003\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.86, 6: 0.17}\n",
      "Epoch: 0217 train_loss= 1.85475 train_acc= 0.96970 val_acc= 0.74661 val_auc= 0.93206 time= 81.75390\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 0.88, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.86, 6: 0.11}\n",
      "Epoch: 0218 train_loss= 1.84449 train_acc= 1.00000 val_acc= 0.75113 val_auc= 0.93331 time= 82.16981\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.81, 6: 0.17}\n",
      "Epoch: 0219 train_loss= 1.85028 train_acc= 0.98485 val_acc= 0.74661 val_auc= 0.93523 time= 82.57969\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.86, 5: 0.8, 4: 0.74, 3: 0.76, 6: 0.22}\n",
      "Epoch: 0220 train_loss= 1.85549 train_acc= 0.98485 val_acc= 0.75113 val_auc= 0.93696 time= 82.99459\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.71, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0221 train_loss= 1.85376 train_acc= 0.92424 val_acc= 0.74208 val_auc= 0.93810 time= 83.41446\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 0.75, 5: 0.88, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.71, 3: 0.67, 6: 0.28}\n",
      "Epoch: 0222 train_loss= 1.84995 train_acc= 1.00000 val_acc= 0.73756 val_auc= 0.93864 time= 83.82781\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.71, 3: 0.62, 6: 0.28}\n",
      "Epoch: 0223 train_loss= 1.84495 train_acc= 0.98485 val_acc= 0.72851 val_auc= 0.93909 time= 84.23173\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.62, 6: 0.28}\n",
      "Epoch: 0224 train_loss= 1.85337 train_acc= 0.98485 val_acc= 0.72851 val_auc= 0.93833 time= 84.62966\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.62, 6: 0.28}\n",
      "Epoch: 0225 train_loss= 1.85630 train_acc= 0.96970 val_acc= 0.74208 val_auc= 0.93708 time= 85.06849\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.9, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0226 train_loss= 1.84859 train_acc= 1.00000 val_acc= 0.76018 val_auc= 0.93547 time= 85.48138\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.71, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0227 train_loss= 1.84651 train_acc= 0.95455 val_acc= 0.75113 val_auc= 0.93452 time= 85.89128\n",
      "train_accuracy_per_classes:{3: 0.82, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.71, 3: 0.81, 6: 0.22}\n",
      "Epoch: 0228 train_loss= 1.84765 train_acc= 0.95455 val_acc= 0.75113 val_auc= 0.93260 time= 86.31413\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.33, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.91, 5: 0.8, 4: 0.71, 3: 0.81, 6: 0.17}\n",
      "Epoch: 0229 train_loss= 1.84539 train_acc= 0.98485 val_acc= 0.75113 val_auc= 0.93131 time= 86.71808\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.91, 5: 0.8, 4: 0.74, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0230 train_loss= 1.84306 train_acc= 0.98485 val_acc= 0.76018 val_auc= 0.93140 time= 87.13494\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.91, 5: 0.8, 4: 0.74, 3: 0.76, 6: 0.22}\n",
      "Epoch: 0231 train_loss= 1.85014 train_acc= 0.96970 val_acc= 0.75566 val_auc= 0.93167 time= 87.55282\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.74, 3: 0.76, 6: 0.22}\n",
      "Epoch: 0232 train_loss= 1.85521 train_acc= 0.98485 val_acc= 0.75566 val_auc= 0.93294 time= 87.95278\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.91, 5: 0.8, 4: 0.74, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0233 train_loss= 1.85995 train_acc= 0.96970 val_acc= 0.74661 val_auc= 0.93360 time= 88.44543\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.9, 5: 0.8, 4: 0.71, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0234 train_loss= 1.84375 train_acc= 1.00000 val_acc= 0.73756 val_auc= 0.93397 time= 88.85836\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0235 train_loss= 1.84258 train_acc= 0.98485 val_acc= 0.73303 val_auc= 0.93501 time= 89.28220\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.91, 5: 0.8, 4: 0.68, 3: 0.67, 6: 0.17}\n",
      "Epoch: 0236 train_loss= 1.84884 train_acc= 1.00000 val_acc= 0.72851 val_auc= 0.93634 time= 89.71208\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.91, 5: 0.8, 4: 0.68, 3: 0.62, 6: 0.17}\n",
      "Epoch: 0237 train_loss= 1.85299 train_acc= 0.96970 val_acc= 0.72398 val_auc= 0.93668 time= 90.09704\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0238 train_loss= 1.84902 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.93578 time= 90.47999\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.71, 3: 0.71, 6: 0.22}\n",
      "Epoch: 0239 train_loss= 1.85057 train_acc= 0.96970 val_acc= 0.74208 val_auc= 0.93487 time= 90.86197\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.71, 3: 0.71, 6: 0.22}\n",
      "Epoch: 0240 train_loss= 1.84789 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.93438 time= 91.24696\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.71, 3: 0.71, 6: 0.22}\n",
      "Epoch: 0241 train_loss= 1.84932 train_acc= 1.00000 val_acc= 0.75566 val_auc= 0.93401 time= 91.62696\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.91, 5: 0.8, 4: 0.71, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0242 train_loss= 1.84479 train_acc= 0.96970 val_acc= 0.71041 val_auc= 0.93362 time= 92.01093\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.64, 0: 0.93, 5: 0.8, 4: 0.68, 3: 0.52, 6: 0.17}\n",
      "Epoch: 0243 train_loss= 1.84787 train_acc= 0.96970 val_acc= 0.70136 val_auc= 0.93452 time= 92.39388\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.64, 0: 0.91, 5: 0.8, 4: 0.68, 3: 0.48, 6: 0.17}\n",
      "Epoch: 0244 train_loss= 1.84706 train_acc= 0.95455 val_acc= 0.73756 val_auc= 0.93537 time= 92.80780\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.62, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.91, 5: 0.8, 4: 0.71, 3: 0.57, 6: 0.22}\n",
      "Epoch: 0245 train_loss= 1.85163 train_acc= 0.98485 val_acc= 0.76018 val_auc= 0.93573 time= 93.20673\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0246 train_loss= 1.85152 train_acc= 0.98485 val_acc= 0.75113 val_auc= 0.93574 time= 93.64852\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0247 train_loss= 1.84515 train_acc= 0.98485 val_acc= 0.74661 val_auc= 0.93598 time= 94.05147\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0248 train_loss= 1.84384 train_acc= 0.98485 val_acc= 0.73303 val_auc= 0.93540 time= 94.49136\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.91, 5: 0.8, 4: 0.68, 3: 0.67, 6: 0.22}\n",
      "Epoch: 0249 train_loss= 1.84166 train_acc= 0.95455 val_acc= 0.72398 val_auc= 0.93398 time= 94.91623\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.64, 0: 0.95, 5: 0.8, 4: 0.68, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0250 train_loss= 1.84579 train_acc= 0.96970 val_acc= 0.72851 val_auc= 0.93284 time= 95.33312\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.64, 0: 0.95, 5: 0.8, 4: 0.68, 3: 0.67, 6: 0.17}\n",
      "Epoch: 0251 train_loss= 1.84276 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.93283 time= 95.80208\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.64, 0: 0.93, 5: 0.8, 4: 0.68, 3: 0.81, 6: 0.17}\n",
      "Epoch: 0252 train_loss= 1.84963 train_acc= 0.96970 val_acc= 0.75566 val_auc= 0.93187 time= 96.24287\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.76, 4: 0.68, 3: 0.86, 6: 0.28}\n",
      "Epoch: 0253 train_loss= 1.84221 train_acc= 1.00000 val_acc= 0.75566 val_auc= 0.93424 time= 96.66973\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0254 train_loss= 1.84502 train_acc= 1.00000 val_acc= 0.74208 val_auc= 0.93653 time= 97.07583\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0255 train_loss= 1.84272 train_acc= 0.98485 val_acc= 0.72851 val_auc= 0.93636 time= 97.49570\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.9, 5: 0.8, 4: 0.71, 3: 0.52, 6: 0.28}\n",
      "Epoch: 0256 train_loss= 1.84658 train_acc= 0.98485 val_acc= 0.71041 val_auc= 0.93567 time= 97.92256\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.48, 6: 0.22}\n",
      "Epoch: 0257 train_loss= 1.84108 train_acc= 1.00000 val_acc= 0.70588 val_auc= 0.93653 time= 98.34546\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.64, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.48, 6: 0.22}\n",
      "Epoch: 0258 train_loss= 1.83960 train_acc= 0.96970 val_acc= 0.72851 val_auc= 0.93797 time= 98.77033\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.67, 0: 0.91, 5: 0.8, 4: 0.68, 3: 0.62, 6: 0.22}\n",
      "Epoch: 0259 train_loss= 1.84845 train_acc= 0.98485 val_acc= 0.75113 val_auc= 0.93756 time= 99.22122\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0260 train_loss= 1.83718 train_acc= 0.96970 val_acc= 0.75566 val_auc= 0.93544 time= 99.67304\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.86, 6: 0.28}\n",
      "Epoch: 0261 train_loss= 1.84080 train_acc= 0.98485 val_acc= 0.74661 val_auc= 0.93494 time= 100.09591\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.81, 6: 0.22}\n",
      "Epoch: 0262 train_loss= 1.84205 train_acc= 1.00000 val_acc= 0.73303 val_auc= 0.93485 time= 100.52873\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.91, 5: 0.8, 4: 0.65, 3: 0.67, 6: 0.17}\n",
      "Epoch: 0263 train_loss= 1.83764 train_acc= 0.98485 val_acc= 0.71493 val_auc= 0.93594 time= 100.94464\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0264 train_loss= 1.84151 train_acc= 0.96970 val_acc= 0.72398 val_auc= 0.93686 time= 101.36549\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0265 train_loss= 1.84460 train_acc= 0.98485 val_acc= 0.72398 val_auc= 0.93808 time= 101.79538\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 0.88, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.62, 6: 0.17}\n",
      "Epoch: 0266 train_loss= 1.84917 train_acc= 1.00000 val_acc= 0.73303 val_auc= 0.93886 time= 102.22922\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.67, 6: 0.22}\n",
      "Epoch: 0267 train_loss= 1.84354 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.93782 time= 102.64508\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.22}\n",
      "Epoch: 0268 train_loss= 1.84470 train_acc= 0.98485 val_acc= 0.76018 val_auc= 0.93674 time= 103.07295\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.74, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0269 train_loss= 1.83881 train_acc= 1.00000 val_acc= 0.76018 val_auc= 0.93621 time= 103.49779\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.9, 5: 0.76, 4: 0.74, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0270 train_loss= 1.84398 train_acc= 0.98485 val_acc= 0.76471 val_auc= 0.93710 time= 103.92667\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.9, 5: 0.8, 4: 0.74, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0271 train_loss= 1.83804 train_acc= 0.96970 val_acc= 0.75113 val_auc= 0.93732 time= 104.35949\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.93, 5: 0.8, 4: 0.74, 3: 0.67, 6: 0.28}\n",
      "Epoch: 0272 train_loss= 1.84446 train_acc= 0.95455 val_acc= 0.72398 val_auc= 0.93574 time= 104.78934\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.64, 0: 0.95, 5: 0.8, 4: 0.68, 3: 0.48, 6: 0.28}\n",
      "Epoch: 0273 train_loss= 1.84736 train_acc= 0.93939 val_acc= 0.72851 val_auc= 0.93574 time= 105.21523\n",
      "train_accuracy_per_classes:{3: 0.82, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.95, 5: 0.8, 4: 0.68, 3: 0.48, 6: 0.28}\n",
      "Epoch: 0274 train_loss= 1.83856 train_acc= 0.96970 val_acc= 0.74208 val_auc= 0.93724 time= 105.65502\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.91, 5: 0.8, 4: 0.68, 3: 0.67, 6: 0.28}\n",
      "Epoch: 0275 train_loss= 1.84694 train_acc= 1.00000 val_acc= 0.75566 val_auc= 0.93652 time= 106.10286\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.84, 5: 0.8, 4: 0.71, 3: 0.86, 6: 0.28}\n",
      "Epoch: 0276 train_loss= 1.83833 train_acc= 0.95455 val_acc= 0.75566 val_auc= 0.93643 time= 106.53570\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.84, 5: 0.8, 4: 0.71, 3: 0.86, 6: 0.28}\n",
      "Epoch: 0277 train_loss= 1.83928 train_acc= 1.00000 val_acc= 0.73756 val_auc= 0.93706 time= 106.95954\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.22}\n",
      "Epoch: 0278 train_loss= 1.84237 train_acc= 1.00000 val_acc= 0.71493 val_auc= 0.93677 time= 107.40037\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.52, 6: 0.17}\n",
      "Epoch: 0279 train_loss= 1.83721 train_acc= 1.00000 val_acc= 0.70136 val_auc= 0.93504 time= 107.83223\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.64, 0: 0.91, 5: 0.8, 4: 0.68, 3: 0.43, 6: 0.17}\n",
      "Epoch: 0280 train_loss= 1.84669 train_acc= 0.96970 val_acc= 0.69683 val_auc= 0.93530 time= 108.22715\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.64, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.48, 6: 0.11}\n",
      "Epoch: 0281 train_loss= 1.83318 train_acc= 0.98485 val_acc= 0.72851 val_auc= 0.93516 time= 108.61810\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.67, 6: 0.17}\n",
      "Epoch: 0282 train_loss= 1.84887 train_acc= 0.98485 val_acc= 0.73756 val_auc= 0.93344 time= 109.03100\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.83, 5: 0.8, 4: 0.71, 3: 0.86, 6: 0.17}\n",
      "Epoch: 0283 train_loss= 1.85080 train_acc= 0.96970 val_acc= 0.72851 val_auc= 0.93296 time= 109.42694\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.83, 5: 0.76, 4: 0.68, 3: 0.86, 6: 0.17}\n",
      "Epoch: 0284 train_loss= 1.84081 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.93511 time= 109.84382\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0285 train_loss= 1.83851 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.93652 time= 110.34749\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.91, 5: 0.8, 4: 0.68, 3: 0.67, 6: 0.17}\n",
      "Epoch: 0286 train_loss= 1.84253 train_acc= 1.00000 val_acc= 0.73303 val_auc= 0.93812 time= 110.78830\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.67, 6: 0.17}\n",
      "Epoch: 0287 train_loss= 1.83983 train_acc= 1.00000 val_acc= 0.72398 val_auc= 0.93890 time= 111.25705\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.62, 6: 0.17}\n",
      "Epoch: 0288 train_loss= 1.83794 train_acc= 1.00000 val_acc= 0.73756 val_auc= 0.93845 time= 111.71781\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0289 train_loss= 1.83957 train_acc= 0.96970 val_acc= 0.73756 val_auc= 0.93735 time= 112.16064\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0290 train_loss= 1.83913 train_acc= 0.98485 val_acc= 0.74661 val_auc= 0.93534 time= 112.59746\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0291 train_loss= 1.84298 train_acc= 1.00000 val_acc= 0.71946 val_auc= 0.93342 time= 113.02335\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.62, 0: 0.93, 5: 0.8, 4: 0.68, 3: 0.62, 6: 0.17}\n",
      "Epoch: 0292 train_loss= 1.84782 train_acc= 0.95455 val_acc= 0.71946 val_auc= 0.93323 time= 113.44121\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.62, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.62, 0: 0.93, 5: 0.8, 4: 0.68, 3: 0.62, 6: 0.17}\n",
      "Epoch: 0293 train_loss= 1.84688 train_acc= 0.98485 val_acc= 0.74661 val_auc= 0.93499 time= 113.86507\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.93, 5: 0.76, 4: 0.68, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0294 train_loss= 1.83607 train_acc= 1.00000 val_acc= 0.75113 val_auc= 0.93762 time= 114.30689\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.91, 5: 0.8, 4: 0.68, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0295 train_loss= 1.83438 train_acc= 0.98485 val_acc= 0.74661 val_auc= 0.94047 time= 114.72979\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.67, 6: 0.28}\n",
      "Epoch: 0296 train_loss= 1.83747 train_acc= 0.98485 val_acc= 0.74661 val_auc= 0.94132 time= 115.14568\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.71, 3: 0.67, 6: 0.28}\n",
      "Epoch: 0297 train_loss= 1.84296 train_acc= 0.98485 val_acc= 0.75113 val_auc= 0.94035 time= 115.54362\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.91, 5: 0.8, 4: 0.71, 3: 0.67, 6: 0.28}\n",
      "Epoch: 0298 train_loss= 1.83794 train_acc= 0.98485 val_acc= 0.73756 val_auc= 0.93861 time= 115.97444\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.68, 3: 0.62, 6: 0.17}\n",
      "Epoch: 0299 train_loss= 1.84334 train_acc= 1.00000 val_acc= 0.74208 val_auc= 0.93643 time= 116.39632\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0300 train_loss= 1.84103 train_acc= 1.00000 val_acc= 0.72851 val_auc= 0.93395 time= 116.83513\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.67, 0: 0.93, 5: 0.8, 4: 0.65, 3: 0.67, 6: 0.17}\n",
      "Epoch: 0301 train_loss= 1.84125 train_acc= 0.98485 val_acc= 0.73756 val_auc= 0.93425 time= 117.26000\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.93, 5: 0.8, 4: 0.65, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0302 train_loss= 1.83296 train_acc= 0.98485 val_acc= 0.73303 val_auc= 0.93643 time= 117.68686\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0303 train_loss= 1.84101 train_acc= 0.96970 val_acc= 0.73756 val_auc= 0.93865 time= 118.10078\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.65, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0304 train_loss= 1.83643 train_acc= 0.98485 val_acc= 0.72398 val_auc= 0.94080 time= 118.53359\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.65, 3: 0.67, 6: 0.17}\n",
      "Epoch: 0305 train_loss= 1.84470 train_acc= 1.00000 val_acc= 0.71946 val_auc= 0.94132 time= 118.97441\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0306 train_loss= 1.84861 train_acc= 0.93939 val_acc= 0.71946 val_auc= 0.94101 time= 119.41823\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 0.67, 2: 0.75, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.91, 5: 0.8, 4: 0.65, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0307 train_loss= 1.83631 train_acc= 1.00000 val_acc= 0.74208 val_auc= 0.94020 time= 119.84609\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.71, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0308 train_loss= 1.84135 train_acc= 0.98485 val_acc= 0.73303 val_auc= 0.93731 time= 120.27796\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.9, 5: 0.76, 4: 0.68, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0309 train_loss= 1.82652 train_acc= 1.00000 val_acc= 0.73303 val_auc= 0.93528 time= 120.69982\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.9, 5: 0.76, 4: 0.68, 3: 0.81, 6: 0.11}\n",
      "Epoch: 0310 train_loss= 1.82828 train_acc= 0.98485 val_acc= 0.73303 val_auc= 0.93635 time= 121.13264\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.9, 5: 0.76, 4: 0.68, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0311 train_loss= 1.83177 train_acc= 0.98485 val_acc= 0.72851 val_auc= 0.93897 time= 121.57347\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0312 train_loss= 1.83381 train_acc= 0.96970 val_acc= 0.71041 val_auc= 0.93867 time= 122.00932\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.48, 6: 0.17}\n",
      "Epoch: 0313 train_loss= 1.84521 train_acc= 0.95455 val_acc= 0.70136 val_auc= 0.93844 time= 122.45810\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.75, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.9, 5: 0.8, 4: 0.62, 3: 0.48, 6: 0.17}\n",
      "Epoch: 0314 train_loss= 1.84345 train_acc= 0.96970 val_acc= 0.71041 val_auc= 0.93953 time= 122.87001\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.62, 3: 0.52, 6: 0.17}\n",
      "Epoch: 0315 train_loss= 1.83866 train_acc= 1.00000 val_acc= 0.72851 val_auc= 0.93662 time= 123.31982\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.62, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0316 train_loss= 1.84505 train_acc= 0.95455 val_acc= 0.73756 val_auc= 0.93416 time= 123.76062\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.65, 3: 0.81, 6: 0.17}\n",
      "Epoch: 0317 train_loss= 1.83643 train_acc= 1.00000 val_acc= 0.73756 val_auc= 0.93301 time= 124.17554\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0318 train_loss= 1.82429 train_acc= 1.00000 val_acc= 0.71946 val_auc= 0.93296 time= 124.61334\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.64, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.67, 6: 0.17}\n",
      "Epoch: 0319 train_loss= 1.84191 train_acc= 1.00000 val_acc= 0.69231 val_auc= 0.93200 time= 125.04126\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.6, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.48, 6: 0.17}\n",
      "Epoch: 0320 train_loss= 1.83370 train_acc= 0.98485 val_acc= 0.71041 val_auc= 0.93465 time= 125.47513\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.52, 6: 0.22}\n",
      "Epoch: 0321 train_loss= 1.83354 train_acc= 1.00000 val_acc= 0.73303 val_auc= 0.93827 time= 125.92789\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.62, 6: 0.28}\n",
      "Epoch: 0322 train_loss= 1.84035 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.93944 time= 126.39366\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0323 train_loss= 1.84406 train_acc= 1.00000 val_acc= 0.74208 val_auc= 0.93848 time= 126.86838\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.65, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0324 train_loss= 1.83599 train_acc= 0.95455 val_acc= 0.74661 val_auc= 0.93848 time= 127.33821\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 0.95, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.8}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.65, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0325 train_loss= 1.83897 train_acc= 0.98485 val_acc= 0.73756 val_auc= 0.93783 time= 127.80939\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.96, 2: 0.74, 0: 0.88, 5: 0.8, 4: 0.65, 3: 0.67, 6: 0.17}\n",
      "Epoch: 0326 train_loss= 1.83516 train_acc= 0.96970 val_acc= 0.71041 val_auc= 0.93683 time= 128.24323\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.75, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0327 train_loss= 1.83086 train_acc= 1.00000 val_acc= 0.71493 val_auc= 0.93628 time= 128.69805\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.93, 5: 0.8, 4: 0.65, 3: 0.52, 6: 0.17}\n",
      "Epoch: 0328 train_loss= 1.83294 train_acc= 0.98485 val_acc= 0.73303 val_auc= 0.93718 time= 129.12091\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.91, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0329 train_loss= 1.84019 train_acc= 0.95455 val_acc= 0.75566 val_auc= 0.93702 time= 129.55977\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.71, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0330 train_loss= 1.82801 train_acc= 1.00000 val_acc= 0.75566 val_auc= 0.93853 time= 129.98760\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.71, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0331 train_loss= 1.83998 train_acc= 0.98485 val_acc= 0.76018 val_auc= 0.94123 time= 130.41545\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.71, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0332 train_loss= 1.84003 train_acc= 0.98485 val_acc= 0.73303 val_auc= 0.94318 time= 130.85134\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.67, 6: 0.17}\n",
      "Epoch: 0333 train_loss= 1.84014 train_acc= 0.96970 val_acc= 0.71041 val_auc= 0.94389 time= 131.27914\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 0.95, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.48, 6: 0.17}\n",
      "Epoch: 0334 train_loss= 1.83243 train_acc= 1.00000 val_acc= 0.72398 val_auc= 0.94296 time= 131.72298\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0335 train_loss= 1.83152 train_acc= 1.00000 val_acc= 0.73756 val_auc= 0.94084 time= 132.12787\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.65, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0336 train_loss= 1.83552 train_acc= 1.00000 val_acc= 0.74208 val_auc= 0.93854 time= 132.54077\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.65, 3: 0.76, 6: 0.22}\n",
      "Epoch: 0337 train_loss= 1.83854 train_acc= 0.98485 val_acc= 0.73303 val_auc= 0.93746 time= 132.98259\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.65, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0338 train_loss= 1.83824 train_acc= 0.96970 val_acc= 0.73303 val_auc= 0.93794 time= 133.38850\n",
      "train_accuracy_per_classes:{3: 0.82, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0339 train_loss= 1.83610 train_acc= 1.00000 val_acc= 0.71946 val_auc= 0.93807 time= 133.83631\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.64, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0340 train_loss= 1.82993 train_acc= 1.00000 val_acc= 0.73303 val_auc= 0.93905 time= 134.26317\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.67, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.76, 6: 0.22}\n",
      "Epoch: 0341 train_loss= 1.83235 train_acc= 0.98485 val_acc= 0.72851 val_auc= 0.94064 time= 134.70299\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.67, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0342 train_loss= 1.83907 train_acc= 0.98485 val_acc= 0.75113 val_auc= 0.94116 time= 135.15481\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.71, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0343 train_loss= 1.82343 train_acc= 0.98485 val_acc= 0.76018 val_auc= 0.94058 time= 135.59460\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.88, 5: 0.8, 4: 0.71, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0344 train_loss= 1.83866 train_acc= 1.00000 val_acc= 0.73756 val_auc= 0.93827 time= 136.01548\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.88, 5: 0.76, 4: 0.68, 3: 0.86, 6: 0.22}\n",
      "Epoch: 0345 train_loss= 1.82173 train_acc= 0.98485 val_acc= 0.73756 val_auc= 0.93633 time= 136.44832\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 0.83, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.88, 5: 0.76, 4: 0.65, 3: 0.86, 6: 0.28}\n",
      "Epoch: 0346 train_loss= 1.83564 train_acc= 1.00000 val_acc= 0.73756 val_auc= 0.93571 time= 136.85232\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.86, 5: 0.76, 4: 0.65, 3: 0.86, 6: 0.28}\n",
      "Epoch: 0347 train_loss= 1.83639 train_acc= 0.96970 val_acc= 0.73303 val_auc= 0.93719 time= 137.25616\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.86, 5: 0.8, 4: 0.65, 3: 0.81, 6: 0.22}\n",
      "Epoch: 0348 train_loss= 1.83484 train_acc= 0.96970 val_acc= 0.73756 val_auc= 0.93855 time= 137.67106\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.81, 6: 0.22}\n",
      "Epoch: 0349 train_loss= 1.82921 train_acc= 0.98485 val_acc= 0.73303 val_auc= 0.93936 time= 138.07798\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.88, 5: 0.8, 4: 0.71, 3: 0.67, 6: 0.22}\n",
      "Epoch: 0350 train_loss= 1.82989 train_acc= 0.98485 val_acc= 0.74208 val_auc= 0.93986 time= 138.48189\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.71, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0351 train_loss= 1.83883 train_acc= 0.96970 val_acc= 0.72851 val_auc= 0.93904 time= 138.88783\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.84, 5: 0.8, 4: 0.68, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0352 train_loss= 1.83209 train_acc= 1.00000 val_acc= 0.72398 val_auc= 0.93874 time= 139.29471\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.67, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.67, 6: 0.17}\n",
      "Epoch: 0353 train_loss= 1.83098 train_acc= 1.00000 val_acc= 0.69231 val_auc= 0.93692 time= 139.72057\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.64, 0: 0.91, 5: 0.8, 4: 0.65, 3: 0.43, 6: 0.17}\n",
      "Epoch: 0354 train_loss= 1.83924 train_acc= 0.98485 val_acc= 0.70588 val_auc= 0.93656 time= 140.12948\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.67, 0: 0.91, 5: 0.8, 4: 0.65, 3: 0.48, 6: 0.17}\n",
      "Epoch: 0355 train_loss= 1.82851 train_acc= 1.00000 val_acc= 0.72851 val_auc= 0.93828 time= 140.55238\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.74, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0356 train_loss= 1.83761 train_acc= 0.98485 val_acc= 0.73756 val_auc= 0.93797 time= 140.95929\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.65, 3: 0.81, 6: 0.17}\n",
      "Epoch: 0357 train_loss= 1.83772 train_acc= 0.96970 val_acc= 0.74208 val_auc= 0.93676 time= 141.36717\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.84, 5: 0.8, 4: 0.65, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0358 train_loss= 1.82664 train_acc= 1.00000 val_acc= 0.74661 val_auc= 0.93751 time= 141.78109\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.96, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.65, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0359 train_loss= 1.82795 train_acc= 0.98485 val_acc= 0.71946 val_auc= 0.93772 time= 142.22588\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.91, 5: 0.8, 4: 0.62, 3: 0.62, 6: 0.17}\n",
      "Epoch: 0360 train_loss= 1.83577 train_acc= 1.00000 val_acc= 0.69231 val_auc= 0.93548 time= 142.66770\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.62, 0: 0.91, 5: 0.8, 4: 0.65, 3: 0.43, 6: 0.17}\n",
      "Epoch: 0361 train_loss= 1.83107 train_acc= 1.00000 val_acc= 0.70136 val_auc= 0.93527 time= 143.09555\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.62, 0: 0.91, 5: 0.8, 4: 0.62, 3: 0.52, 6: 0.22}\n",
      "Epoch: 0362 train_loss= 1.84178 train_acc= 0.96970 val_acc= 0.73756 val_auc= 0.93512 time= 143.54635\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.64, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.76, 6: 0.28}\n",
      "Epoch: 0363 train_loss= 1.83150 train_acc= 1.00000 val_acc= 0.73303 val_auc= 0.93278 time= 143.97424\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.83, 5: 0.8, 4: 0.68, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0364 train_loss= 1.83757 train_acc= 0.95455 val_acc= 0.75113 val_auc= 0.93397 time= 144.42799\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.75, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.91, 5: 0.8, 4: 0.62, 3: 0.86, 6: 0.28}\n",
      "Epoch: 0365 train_loss= 1.82921 train_acc= 1.00000 val_acc= 0.73756 val_auc= 0.93354 time= 144.83490\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.96, 2: 0.67, 0: 0.93, 5: 0.8, 4: 0.62, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0366 train_loss= 1.82836 train_acc= 0.96970 val_acc= 0.70588 val_auc= 0.93384 time= 145.25478\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.93, 5: 0.8, 4: 0.62, 3: 0.48, 6: 0.17}\n",
      "Epoch: 0367 train_loss= 1.82539 train_acc= 0.98485 val_acc= 0.71041 val_auc= 0.93557 time= 145.69061\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.95, 5: 0.8, 4: 0.65, 3: 0.43, 6: 0.17}\n",
      "Epoch: 0368 train_loss= 1.83102 train_acc= 1.00000 val_acc= 0.74661 val_auc= 0.93894 time= 146.15737\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0369 train_loss= 1.83521 train_acc= 1.00000 val_acc= 0.75113 val_auc= 0.94050 time= 146.59622\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0370 train_loss= 1.82896 train_acc= 1.00000 val_acc= 0.74661 val_auc= 0.94018 time= 147.02008\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0371 train_loss= 1.84405 train_acc= 0.93939 val_acc= 0.74208 val_auc= 0.94074 time= 147.49480\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.75, 5: 0.88, 1: 1.0, 4: 0.9}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.71, 6: 0.28}\n",
      "Epoch: 0372 train_loss= 1.84091 train_acc= 0.96970 val_acc= 0.71041 val_auc= 0.94003 time= 147.96958\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.48, 6: 0.17}\n",
      "Epoch: 0373 train_loss= 1.82822 train_acc= 1.00000 val_acc= 0.71041 val_auc= 0.93867 time= 148.47317\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.43, 6: 0.17}\n",
      "Epoch: 0374 train_loss= 1.83048 train_acc= 1.00000 val_acc= 0.72398 val_auc= 0.93905 time= 148.92200\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.96, 2: 0.71, 0: 0.9, 5: 0.76, 4: 0.62, 3: 0.57, 6: 0.22}\n",
      "Epoch: 0375 train_loss= 1.83902 train_acc= 1.00000 val_acc= 0.73756 val_auc= 0.93680 time= 149.38177\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.96, 2: 0.71, 0: 0.84, 5: 0.76, 4: 0.62, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0376 train_loss= 1.83348 train_acc= 0.98485 val_acc= 0.71946 val_auc= 0.93470 time= 149.82259\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.81, 5: 0.8, 4: 0.65, 3: 0.76, 6: 0.22}\n",
      "Epoch: 0377 train_loss= 1.82832 train_acc= 1.00000 val_acc= 0.72398 val_auc= 0.93659 time= 150.25245\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0378 train_loss= 1.82930 train_acc= 1.00000 val_acc= 0.70136 val_auc= 0.93328 time= 150.69424\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.6, 0: 0.9, 5: 0.8, 4: 0.68, 3: 0.62, 6: 0.17}\n",
      "Epoch: 0379 train_loss= 1.82472 train_acc= 1.00000 val_acc= 0.66968 val_auc= 0.92878 time= 151.11219\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.74, 2: 0.57, 0: 0.93, 5: 0.8, 4: 0.62, 3: 0.43, 6: 0.17}\n",
      "Epoch: 0380 train_loss= 1.82340 train_acc= 0.96970 val_acc= 0.70136 val_auc= 0.93230 time= 151.53502\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.62, 0: 0.91, 5: 0.8, 4: 0.65, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0381 train_loss= 1.82045 train_acc= 0.98485 val_acc= 0.72851 val_auc= 0.93558 time= 151.98080\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.67, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.71, 6: 0.22}\n",
      "Epoch: 0382 train_loss= 1.82394 train_acc= 1.00000 val_acc= 0.72851 val_auc= 0.93563 time= 152.41264\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.88, 5: 0.76, 4: 0.59, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0383 train_loss= 1.82920 train_acc= 1.00000 val_acc= 0.72398 val_auc= 0.93468 time= 152.86543\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.86, 5: 0.76, 4: 0.59, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0384 train_loss= 1.83523 train_acc= 1.00000 val_acc= 0.74661 val_auc= 0.93774 time= 153.29731\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.96, 2: 0.71, 0: 0.88, 5: 0.76, 4: 0.62, 3: 0.81, 6: 0.28}\n",
      "Epoch: 0385 train_loss= 1.83678 train_acc= 0.98485 val_acc= 0.71946 val_auc= 0.93863 time= 153.74309\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.96, 2: 0.69, 0: 0.91, 5: 0.76, 4: 0.62, 3: 0.52, 6: 0.22}\n",
      "Epoch: 0386 train_loss= 1.83409 train_acc= 1.00000 val_acc= 0.70588 val_auc= 0.93701 time= 154.17275\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.64, 0: 0.91, 5: 0.8, 4: 0.65, 3: 0.52, 6: 0.17}\n",
      "Epoch: 0387 train_loss= 1.83044 train_acc= 1.00000 val_acc= 0.70588 val_auc= 0.93538 time= 154.62452\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.83, 2: 0.64, 0: 0.91, 5: 0.8, 4: 0.65, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0388 train_loss= 1.83583 train_acc= 0.98485 val_acc= 0.73756 val_auc= 0.93452 time= 155.04838\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.69, 0: 0.88, 5: 0.8, 4: 0.68, 3: 0.81, 6: 0.17}\n",
      "Epoch: 0389 train_loss= 1.83376 train_acc= 1.00000 val_acc= 0.74208 val_auc= 0.93446 time= 155.51613\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.87, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.68, 3: 0.86, 6: 0.17}\n",
      "Epoch: 0390 train_loss= 1.83275 train_acc= 1.00000 val_acc= 0.73756 val_auc= 0.93677 time= 155.95196\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.65, 3: 0.81, 6: 0.17}\n",
      "Epoch: 0391 train_loss= 1.82787 train_acc= 0.98485 val_acc= 0.72851 val_auc= 0.93850 time= 156.40475\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 0.67, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.96, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.62, 3: 0.71, 6: 0.17}\n",
      "Epoch: 0392 train_loss= 1.82951 train_acc= 1.00000 val_acc= 0.71041 val_auc= 0.93889 time= 156.85455\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.96, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.62, 3: 0.52, 6: 0.17}\n",
      "Epoch: 0393 train_loss= 1.83507 train_acc= 0.96970 val_acc= 0.70588 val_auc= 0.93865 time= 157.30138\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.96, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.62, 3: 0.48, 6: 0.17}\n",
      "Epoch: 0394 train_loss= 1.83123 train_acc= 1.00000 val_acc= 0.72851 val_auc= 0.93718 time= 157.77709\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.64, 0: 0.9, 5: 0.8, 4: 0.65, 3: 0.76, 6: 0.17}\n",
      "Epoch: 0395 train_loss= 1.82633 train_acc= 1.00000 val_acc= 0.74208 val_auc= 0.93452 time= 158.22190\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.62, 0: 0.93, 5: 0.8, 4: 0.68, 3: 0.81, 6: 0.17}\n",
      "Epoch: 0396 train_loss= 1.82918 train_acc= 0.95455 val_acc= 0.73756 val_auc= 0.93378 time= 158.67668\n",
      "train_accuracy_per_classes:{3: 0.82, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.84, 5: 0.8, 4: 0.71, 3: 0.86, 6: 0.17}\n",
      "Epoch: 0397 train_loss= 1.83441 train_acc= 1.00000 val_acc= 0.73756 val_auc= 0.93574 time= 159.14343\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.81, 5: 0.8, 4: 0.74, 3: 0.86, 6: 0.22}\n",
      "Epoch: 0398 train_loss= 1.82491 train_acc= 1.00000 val_acc= 0.75113 val_auc= 0.94016 time= 159.58628\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.69, 0: 0.86, 5: 0.8, 4: 0.71, 3: 0.86, 6: 0.22}\n",
      "Epoch: 0399 train_loss= 1.83012 train_acc= 0.98485 val_acc= 0.71493 val_auc= 0.94206 time= 160.02707\n",
      "train_accuracy_per_classes:{3: 1.0, 0: 1.0, 6: 1.0, 2: 0.88, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.71, 0: 0.86, 5: 0.8, 4: 0.65, 3: 0.57, 6: 0.17}\n",
      "Epoch: 0400 train_loss= 1.83776 train_acc= 0.98485 val_acc= 0.71041 val_auc= 0.94042 time= 160.50582\n",
      "train_accuracy_per_classes:{3: 0.91, 0: 1.0, 6: 1.0, 2: 1.0, 5: 1.0, 1: 1.0, 4: 1.0}\n",
      "val_accuracy_per_classes:{1: 0.91, 2: 0.67, 0: 0.91, 5: 0.8, 4: 0.65, 3: 0.48, 6: 0.17}\n",
      "test_acc= 0.73649 test_auc= 0.93985\n",
      "test_accuracy_per_classes:{0: 0.93, 1: 0.8, 2: 0.61, 3: 0.72, 4: 0.73, 5: 0.77, 6: 0.12}\n"
     ]
    }
   ],
   "source": [
    "from run import drgcn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
